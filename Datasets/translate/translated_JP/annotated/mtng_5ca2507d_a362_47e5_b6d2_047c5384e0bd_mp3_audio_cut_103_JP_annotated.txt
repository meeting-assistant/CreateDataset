SP_1: Предположим, что мы не знаем, сколько денег соберется - 300, 300, 500. Но если мы запустим эти 500 данных через GPT-3, они сразу станут дешевле. Используя GPT-3, мы можем оптимизировать каждую задачу. То есть, в чем суть? Наша модель предварительно обучена и донастроена с помощью GPT-3. Мы просто вводим текст без промпта. Затем он выводится в формате JSON, и мы извлекаем все задачи, которые мы обучили. Таким образом, мы можем комбинировать GPT-3.5 и донастроенную модель. То же самое можно сделать с Yandex, GPT и GigaChat. Я не знаю, насколько это возможно. Идея заключается в следующем:
SP_2: А, понятно. Подождите немного, у меня пропал ручка.
SP_1: После обучения различных моделей с помощью GPT-3.5, мы можем получить различные резюме с помощью gigaChat, Yandex, Anthropiki и т. д. Различные задачи будут ясно классифицированы. Мы можем ранжировать результаты для одной и той же задачи и отмечать те, которые показали хорошие и плохие результаты. То есть мы можем обучить модель-критика, которая будет оценивать качество для одной и той же задачи и давать оценку. Это действительно замечательно. Пока это все еще неизвестно.
SP_2: Критик тоже должен обучаться на входных данных, верно?
SP_1: Да, критик также использует набор данных, но генерирует метки как для хороших, так и для плохих результатов. То есть количество меток увеличивается в 3-4 раза.
SP_2: Возможно, их нужно собирать от пользователей, понятно.
SP_1: Да, затем происходит синхронизация. Верно. И когда набирается достаточное количество пользователей, мы определяем способ измерения качества для каждого пользователя. Затем мы извлекаем данные и повторно обучаем критика на данных, помеченных высококачественными пользователями. Однако это требует большого объема данных. Понятно?