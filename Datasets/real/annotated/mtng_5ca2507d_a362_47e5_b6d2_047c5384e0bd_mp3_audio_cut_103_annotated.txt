SP_1: Допустим, насобирать, скажем, 300, ну, 300, 500, ну, не знаю, сколько денег получится. Вот эти 500 данных запустить на GPT-3, и у нас сразу станет дешевле. Если мы будем через GPT-3, скажем, все прогонять, то мы так можем оптимизацию сделать за по задачем. То есть, что фишка заключается в чем? У нас наша модель, зафреженная и fine-tune в GPT-3. И мы сразу кидаем туда текст без всяких промптов. И она сразу выдает JSON и вытащенные все задачи, как мы ее обучили. То есть мы таким способом <unknown> объединим GPT-3.5 плюс, все, что сделаем fine-tune. Также можно сделать и с Яндексом, и с GPT, и с Гигачатом. Я не знаю, насколько это можно сделать. Идея такая заключается. 
SP_2: Ага. Сейчас я вот <unkown>куда-то ручка делась, сейчас, ладно. 
SP_1: потом смотри как как можно развивать эту тему ну допустим после того как мы обучили все разные модели на GPT-3.5  скажем gigaChat, яндексе там неважно антропики и так далее у нас получится куча разных summary.  Куча разных задач точнее выделено. Вот и потом можно сделать короче разметить те которые обучены хорошо и те обучены которые выдали более-менее плохой результат то есть ранжирование результата сделать для одной и той же задачи и потом обучить модель критика который может критиковать давать оценку качества этим задачам и вот это вообще будет круто потому что сейчас <unknown>
SP_2: А критика тоже надо будет обучать по каким-то входным критика <unkown>
SP_1: Да критику мы тоже возьмем это дата сета но мы сгенерируем как хорошие так и плохие плохую разметку то есть у нас разметка сразу в три-четыре раза скажем увеличивается 
SP_2: собирать от пользователей скорее всего и самих, ну ладно,  я понял 
SP_1: да потом как идет проходит синхронизация. Правильно. А потом мы выравниваем вот эту разметку допустим когда пользователи мы же наберем определенное количество и определим, как мы по пользователям будем мерить качество. Мы эти данные извлекаем, соответственно, и критика потом дообучаем уже на данных, которые разметили уже пользователи качественно. Но это уже когда много данных пойдет. Понял, да?